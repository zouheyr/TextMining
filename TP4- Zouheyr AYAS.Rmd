---
title: "Travail individuel 4"
author: "Zouheyr AYAS"
output:
  word_document: default
  html_notebook: default
  pdf_document: default
---

# Importation les librairies

```{r}
# Installer les packages
#install.packages("tm") # for text mining
#install.packages("SnowballC") # for text stemming
#install.packages("wordcloud") # word-cloud generator
#install.packages("RColorBrewer") # color palettes
#install.packages("syuzhet") # for sentiment analysis
#install.packages("ggplot2") # for plotting graphs
# Charger les libraries
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("syuzhet")
library("ggplot2")
```

# Lecture de texte

```{r}
text <- readLines(file.choose())
```

# Chargement des données sous forme de  corpus

```{r}
TextDoc <- Corpus(VectorSource(text))
```
# Netoyage
```{r}
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
TextDoc <- tm_map(TextDoc, toSpace, "/")
TextDoc <- tm_map(TextDoc, toSpace, "200")
TextDoc <- tm_map(TextDoc, toSpace, "\\|")
TextDoc <- tm_map(TextDoc, toSpace,"™")
TextDoc <- tm_map(TextDoc, toSpace,"€")  
TextDoc <- tm_map(TextDoc, toSpace,"â")
TextDoc <- tm_map(TextDoc, toSpace,"“")
TextDoc <- tm_map(TextDoc, toSpace,"”")
TextDoc <- tm_map(TextDoc, toSpace,"€”") 
```

# Transformation en miniscule, élimination des chiffres, et autres
```{r}
TextDoc <- tm_map(TextDoc, content_transformer(tolower))
TextDoc <- tm_map(TextDoc, removeNumbers)
TextDoc <- tm_map(TextDoc, removeWords, stopwords("english"))
TextDoc <- tm_map(TextDoc, removeWords, c("s", "company","team"))
TextDoc <- tm_map(TextDoc, removePunctuation)
TextDoc <- tm_map(TextDoc, stripWhitespace)
TextDoc <- tm_map(TextDoc, stemDocument)

class(TextDoc)
inspect(TextDoc[[7]])
```

# La Matrice “Termes par Document”

```{r}
TextDoc_dtm <- TermDocumentMatrix(TextDoc)
inspect(TextDoc_dtm)
dtm_m <- as.matrix(TextDoc_dtm)
```

La Matrice “Termes par Document” (suite) 

```{r}
dtm_v <- sort(rowSums(dtm_m),decreasing=TRUE)
dtm_d <- data.frame(word = names(dtm_v),freq=dtm_v)
```

Afficher les mot les plus fréquents , ici on a choisit 15

```{r}
head(dtm_d, 15)
```

Tracer ces mots par un barplot()

```{r}
barplot(dtm_d[1:5,]$freq,
        las = 2,
        names.arg = dtm_d[1:5,]$word,
        col ="lightblue",
        main ="Top 5 des mots les plus fréquents",
        ylab = "Fréquence des mots"
        )
```

Génération d'un nuage de mots (word cloud)

```{r}
set.seed(1234)
wordcloud(words = dtm_d$word,
          freq = dtm_d$freq,
          min.freq = 5,
          max.words=50,
          random.order=FALSE,
          rot.per=0.40,
          colors=brewer.pal(8, "Dark2")
          )
```
Génération des associations


```{r}
# Trouver des associations
findAssocs(TextDoc_dtm, terms = c("war","peace","peopl"), corlimit = 0.25)
```


```{r}
# Trouver des associations pour des mots qui se produisent au moins 50 fois
findAssocs(TextDoc_dtm,
           terms = findFreqTerms(TextDoc_dtm, lowfreq = 50),
           corlimit = 0.25)
```

Score des sentiments

```{r}
syuzhet_vector <- get_sentiment(text,method="syuzhet")
head(syuzhet_vector)
summary(syuzhet_vector)
```
 

```{r}
#par la methode bing
bing_vector <- get_sentiment(text, method="bing")
head(bing_vector)
summary(bing_vector)
#par la metheode affin
afinn_vector <- get_sentiment(text, method="afinn")
head(afinn_vector)
summary(afinn_vector)
```

Extraction des émotions

```{r}
d<-get_nrc_sentiment(text)
head (d,10)
```

Classification des émotions (suite)

```{r}
td<-data.frame(t(d))
td_new <- data.frame(rowSums(td[2:10]))
names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]

```

Classification des émotions - nombre de mots associés à chaque sentiment

```{r}
quickplot(sentiment,
          data=td_new2,
          weight=count,
          geom="bar",
          fill=sentiment,
          ylab="count")+
  ggtitle("Survey sentiments")
```

Classification des émotions (suite)

```{r}

barplot(
        sort(
          colSums(prop.table(d[, 1:8]))
          ),
        horiz = TRUE,
        cex.names = 0.7,
        las = 1,
        main = "Emotions in Text",
        xlab="Percentage",
        col="blue"
  )
```
# Commentaires

Cette analyse de text du président Bill Clinton, lors de son discours annuel 
tant que president des etats unis, nous montre plein de confiance avec esprit
d'anticipation et un sentiement de peur.
Il a cité,les mots 'americans', 'must' , 'year' , 'will' , qui peut signifier 
son intention de faire quelques chose cette année pour les americans.

